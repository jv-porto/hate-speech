{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kIetbkkkN5b"
      },
      "source": [
        "Código com base no repositório [Bert_HateSpeech_Classification](https://github.com/cewebbr/Bert_HateSpeech_Classification) de Diogo Cortiz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mrc7mM2gkN5c"
      },
      "outputs": [],
      "source": [
        "#Importar o Pytorch e HuggingFace (transformers e tokenizers)\n",
        "\n",
        "import torch\n",
        "from transformers import BertModel, BertForMaskedLM, PreTrainedTokenizer\n",
        "from tokenizers import BertWordPieceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvdYBv6PkN5d",
        "outputId": "aa864f3a-6889-47d1-9a54-eb7f89144b24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X60WmOEKkN5d"
      },
      "source": [
        "\"\"\"OPCIONAL: Pode ativar um debbug para entender melhor o que acontece\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1DeGCX8dkN5e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ-tRDx7kN5e"
      },
      "source": [
        "## Pré-processando o Dataset\n",
        "\n",
        "Na pasta, existem duas pastas. Precisamos usar os dados brutos (raw) para que possamos criar os token usando o BertTokenizer. Não podemos usar as setenças tokenizadas porque o processo utilizado na criação desses tokens foi diferente do usado pelo Bert.\n",
        "\n",
        "Iremos utilizar o pandas para manipular as entradas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JazZ0GM1lVOP"
      },
      "outputs": [],
      "source": [
        "## PARA RODAR NO GOOGLE COLAB\n",
        "colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE6dmjEfkwfK",
        "outputId": "988df96b-05ba-4e33-b12a-ab8b97a209ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.11/dist-packages (3.2)\n"
          ]
        }
      ],
      "source": [
        "import wget\n",
        "import pandas as pd\n",
        "\n",
        "if colab:\n",
        "  !pip install wget\n",
        "  wget.download(\"https://raw.githubusercontent.com/paulafortuna/Portuguese-Hate-Speech-Dataset/refs/heads/master/2019-05-28_portuguese_hate_speech_binary_classification.csv\")\n",
        "  df = pd.read_csv(\"2019-05-28_portuguese_hate_speech_binary_classification.csv\", on_bad_lines='skip')\n",
        "else:\n",
        "  df = pd.read_csv(\"../../data/2019-05-28_portuguese_hate_speech_binary_classification.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "gBtEq7kjmarZ",
        "outputId": "8643896b-0dc7-4465-9048-9fe77524b70f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5670,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5666,\n        \"samples\": [\n          \"RT @pauloap: Porra, olha a s\\u00e9rie de reportagens que o Jornal da Record estreia hoje, nunca que a Globo faria https://t.co/1QzI4oabRD\",\n          \"RT @g1: Movimentos sociais e coletivos feministas protestam por direitos da mulher em SP https://t.co/5GJ3xjSPqB #DiadaMulher #G1 https://t _\",\n          \"RT @waldoisnearby: Apresento-vos o meu missil, AEN17.\\nTotalmente dirigida para Angola sem d\\u00f3 e piedade! Se Angola n\\u00e3o \\u00e9 nossa, mais vale n _\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hatespeech_comb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hatespeech_G1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotator_G1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"D\",\n          \"E\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hatespeech_G2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.46128447325839694,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotator_G2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"V\",\n          \"B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hatespeech_G3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"annotator_G3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"C\",\n          \"B\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-cc5d455e-f255-4b00-829b-83d799a0ea8d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>hatespeech_comb</th>\n",
              "      <th>hatespeech_G1</th>\n",
              "      <th>annotator_G1</th>\n",
              "      <th>hatespeech_G2</th>\n",
              "      <th>annotator_G2</th>\n",
              "      <th>hatespeech_G3</th>\n",
              "      <th>annotator_G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@__andrea__b \\nO cara vive em outro mundo\\nNão...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>V</td>\n",
              "      <td>0</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@_carmeloneto Estes incompetentes não cuidam n...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>D</td>\n",
              "      <td>0.0</td>\n",
              "      <td>V</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@_carmeloneto \\nOs 'cumpanhero' quebraram toda...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>0.0</td>\n",
              "      <td>B</td>\n",
              "      <td>0</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@_GlitteryKisses é isso não conseguem pensar n...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>C</td>\n",
              "      <td>0.0</td>\n",
              "      <td>V</td>\n",
              "      <td>0</td>\n",
              "      <td>D</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@_iglira bom dia macaco branco haha</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I</td>\n",
              "      <td>1</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc5d455e-f255-4b00-829b-83d799a0ea8d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cc5d455e-f255-4b00-829b-83d799a0ea8d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cc5d455e-f255-4b00-829b-83d799a0ea8d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b80421e-af33-490e-bf13-9844bc8f8704\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b80421e-af33-490e-bf13-9844bc8f8704')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b80421e-af33-490e-bf13-9844bc8f8704 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text  hatespeech_comb  \\\n",
              "0  @__andrea__b \\nO cara vive em outro mundo\\nNão...                1   \n",
              "1  @_carmeloneto Estes incompetentes não cuidam n...                0   \n",
              "2  @_carmeloneto \\nOs 'cumpanhero' quebraram toda...                0   \n",
              "3  @_GlitteryKisses é isso não conseguem pensar n...                0   \n",
              "4                @_iglira bom dia macaco branco haha                1   \n",
              "\n",
              "   hatespeech_G1 annotator_G1  hatespeech_G2 annotator_G2  hatespeech_G3  \\\n",
              "0              1            A            1.0            V              0   \n",
              "1              1            D            0.0            V              0   \n",
              "2              1            A            0.0            B              0   \n",
              "3              0            C            0.0            V              0   \n",
              "4              0            A            1.0            I              1   \n",
              "\n",
              "  annotator_G3  \n",
              "0            E  \n",
              "1            C  \n",
              "2            E  \n",
              "3            D  \n",
              "4            E  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXCnAbENkN5f"
      },
      "source": [
        "## Formatando a Entrada e Criando os Tokens e IDS\n",
        "\n",
        "Agora chegou a hora de criarmos os tokens para que depois eles possam ser mapeados para os index do vocabulário.<Br>\n",
        "Para isso, utilizaremos o BertTokenizer, que já importamos anteriormente. Utilizaremos a versão 'bert-based-unscased' (inglês).<br>\n",
        "Antes disso, no entanto, precisamos formatar a entrada para respeitar os requisitos de entrada do Bert, que são os seguintes:\n",
        "\n",
        "\n",
        "1.   Adicionar tokens especiais no início e no fim de cada sentença ([CLS] para o início de uma sentença de classificação / [SEP] para indicar o fim de uma sentença.\n",
        "\n",
        "<img src=\"http://www.mccormickml.com/assets/BERT/CLS_token_500x606.png\" alt=\"placeholder\" width=\"50%\" height=\"50%\">\n",
        "\n",
        "2. Precisamos fazer o Pad e Truncate para que todas as senteças tenham o mesmo tamanho de entrada (máximo de 512 tokens).\n",
        "\n",
        "3. Diferenciar o que são tokens reais dos token de padding, criando um \"attention mask\".\n",
        "<img src=\"http://www.mccormickml.com/assets/BERT/padding_and_mask.png\" alt=\"placeholder\" width=\"50%\" height=\"50%\">\n",
        "\n",
        "## Entendendo o Tokenizer<br>\n",
        "O modelo do Google tem um vocabulário de 30.000 tokens com aprox 768 dimensões cada (embeedings).<br>\n",
        "Os Tokens podem representar palavras completas (mas não todas) <br>\n",
        "Os Tokens podem representar sub-palavras de palavras desconhecidas (as subwords são iniciadas com ##. Reparem que a palavra Diogo não existe no vocabulário. Ela é quebrada em duas subwords: Dio + ##go. Atenção: O token go é diferente do ##go) <oov><br>\n",
        "Os Tokens podem representar caracteres e marcações especiais:<br>\n",
        "[PAD]: Padding<br>\n",
        "[UNK]:Unknow<br>\n",
        "[CLS]: Classificação<br>\n",
        "[SEP]: Separação das sentenças<br>\n",
        "[MASK]: Máscara para a palavra<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_xQE-VJBkN5g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "# USA O MODULO TOKENIZER DO HUGGINFACE\n",
        "from tokenizers import (ByteLevelBPETokenizer,\n",
        "                            SentencePieceBPETokenizer,\n",
        "                            BertWordPieceTokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tokenizer_and_tokenize(sentencas, vocab_path=\"vocab.txt\", colab=False, max_length=60):\n",
        "    \"\"\"\n",
        "    Cria o tokenizer BertWordPieceTokenizer e tokeniza as sentenças em batch.\n",
        "    Retorna o tokenizer, os ids, a attention_mask e o output bruto.\n",
        "    \"\"\"\n",
        "    import wget\n",
        "    from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "    # Baixa o vocabulário se estiver no Colab\n",
        "    if colab:\n",
        "        wget.download(\"https://huggingface.co/neuralmind/bert-base-portuguese-cased/raw/main/vocab.txt\")\n",
        "\n",
        "    # Cria o tokenizer\n",
        "    tokenizer = BertWordPieceTokenizer(vocab_path, lowercase=False, strip_accents=False)\n",
        "\n",
        "    # Configura truncamento e padding\n",
        "    tokenizer.enable_truncation(max_length=max_length)\n",
        "    tokenizer.enable_padding()\n",
        "\n",
        "    # Tokeniza em batch\n",
        "    output = tokenizer.encode_batch(sentencas)\n",
        "\n",
        "    # Extrai ids e attention_mask\n",
        "    ids = [x.ids for x in output]\n",
        "    attention_mask = [x.attention_mask for x in output]\n",
        "\n",
        "    print(len(ids))\n",
        "    print(len(attention_mask))\n",
        "    print(output[0])\n",
        "    print(output[0].tokens)\n",
        "\n",
        "    return tokenizer, ids, attention_mask, output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = df['hatespeech_comb'].values\n",
        "sentencas = [sentenca.lower() for sentenca in df['text'].values]\n",
        "tokenizer, ids, attention_mask, output = create_tokenizer_and_tokenize(sentencas, vocab_path=\"vocab.txt\", colab=colab, max_length=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1-qewEGkN5g"
      },
      "source": [
        "## Dividindo o Dataset em Treinamento e Validação\n",
        "\n",
        "Vamos usar a ferramenta do ScikitLearn para nos ajudar neste processo. Vamos dividir o dataset em 80% para treinamento e 20% para a validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffXD0owykN5g",
        "outputId": "48f1d093-5015-4be3-a70a-cbe5e192e44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[101, 6434, 11842, 698, 8094, 100, 10161, 127, 4522, 3306, 4863, 1141, 106, 291, 117, 271, 13105, 22278, 137, 528, 1927, 6288, 8393, 1604, 117, 253, 1203, 16188, 159, 123, 651, 106, 108, 139, 22298, 22285, 108, 734, 1111, 451, 6702, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#USAR O MESMO RANDON_STATE PARA NAO TROCAR OS INPUTS DE SUAS MÁSCARAS\n",
        "train_input, validation_input, train_labels, validation_labels = train_test_split(ids, labels, random_state=2018, test_size=0.2)\n",
        "train_mask, validation_mask, _, _ = train_test_split(attention_mask, labels, random_state=2018, test_size=0.2)\n",
        "\n",
        "#COMPARANDO A PRIMEIRA LINHA DE TREINAMENTO COM A MASCARA\n",
        "print(train_input[0])\n",
        "print(train_mask[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8EMQC99kN5g"
      },
      "source": [
        "## Criando os tensores (Pytorch Data Type)\n",
        "Os modelos do PyTorch esperam de entrada o tipo tensor, então precisamos converter o nosso dataset de Numpy Array para tensores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MJNCeSVXkN5g"
      },
      "outputs": [],
      "source": [
        "train_input_tensor = torch.tensor(train_input)\n",
        "validation_input_tensor = torch.tensor(validation_input)\n",
        "\n",
        "train_labels_tensor = torch.tensor(train_labels)\n",
        "validation_labels_tensor = torch.tensor(validation_labels)\n",
        "\n",
        "train_mask_tensor = torch.tensor(train_mask)\n",
        "validation_mask_tensor= torch.tensor(validation_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF4-Bye8kN5g"
      },
      "source": [
        "Uma ação adicional é usar o torch DataLoader, que cria um \"iterator\". Diferente de um for, o iterador não sobe todo o dataset não precisa ser carregado todo na memória (ajuda no treinamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mChWL4ofkN5h"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#É PRECISO ESPECIFICAR O TAMANHO DO BATCH, PARA O BERT OS AUTORES RECOMENDAM 16 OU 32\n",
        "batch_size = 32\n",
        "\n",
        "#CRIA OS DATALOADERS PARA O CONJUNTO DE TREINAMENTO\n",
        "train_data = TensorDataset(train_input_tensor, train_mask_tensor, train_labels_tensor)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "#CRIA OS DATALOADRES PARA O CONJUNTO DE VALIDAÇÃO\n",
        "validation_data = TensorDataset(validation_input_tensor, validation_mask_tensor, validation_labels_tensor)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIuIGLJEkN5h"
      },
      "source": [
        "## Treinando o modelo\n",
        "O Bert oferece um modelo pré-treinando a qual só precisamos fazer fine-tune para a tarefas que desejamos. O huggingface disponibiza não só o modelo pré-treinado mas também interfaces para nossas tarefas específicas. Algumas disponíveis são:\n",
        "\n",
        "\n",
        "*   BertMode\n",
        "*   BertForMaskedLM\n",
        "*   BertForNextSentencePrediction\n",
        "*   BertForSequenceClassification (vamos usar este)\n",
        "*   BertForTokenClassification\n",
        "*   BertForQuestionAnsering\n",
        "\n",
        "O BertForSequenceClassification basicamente é a implementação do modelo Bert com a adição de uma camada de FFN para classificação. Lembre-se que o hugging face disponibilizou diversas versões de modelo pré-treinanda (base, large, multilanugage). Você pode escolher a que for melhor para o seu propósito. Neste caso, vamos utilizar a versão multilingual por contemplar o português."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvvfQ_-skN5h",
        "outputId": "f2fb7d85-af9d-4913-bc04-36f3a3976df3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#IMPORTA O BERT E O OTIMIZADOR ADAM\n",
        "from transformers import BertForSequenceClassification, BertConfig, BertModel\n",
        "\n",
        "#CRIA O MODELO BERT PRETREINADO COM UMA CAMADA DE CLASSIFICAÇÃO NO TOPO\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'neuralmind/bert-base-portuguese-cased',\n",
        "    num_labels = 2, # NUMERO DE CLASSES (NO CASO BINÁRIA: ACEITÁVEL OU NÃO. PODE TER MAIS PARA MULTICLASSE)\n",
        "    output_attentions = True, # SE O MODELO DEVE EXPORTAR OS PESOS DAS ATENÇÕES\n",
        "    output_hidden_states = True, # SE O MODELO DEVE EXPORTAR OS HIDDEN STATES (PODE SER INTERESSANTE PARA ESTUDAR EMBEDDINGS)\n",
        ")\n",
        "\n",
        "# DIZ AO MODELO PARA USAR GPU\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8-Rcg2MkN5h"
      },
      "source": [
        "\n",
        "## Exibindo parâmetros do modelo\n",
        "Uma curiosidade disponibilizada em (https://mccormickml.com/2019/07/22/BERT-fine-tuning/) <br>\n",
        "É possível mostrar os parâmetro do modelo:\n",
        "<br>\n",
        "*   A camada de embeddings\n",
        "*   A primeira das 12 camadas de transformers\n",
        "*   A camada de saída (output)\n",
        "\n",
        "A execução do trecho abaixo é optativa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERmm64D2kN5h",
        "outputId": "e61e8667-411c-43e1-f868-aec575de7a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (29794, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZwSG6VukN5i"
      },
      "source": [
        "## Otimizador\n",
        "\n",
        "Carregamos o modelo, agora precisamos criar o Otimizador Adam. Os autores recomendam os seguintres valores:\n",
        "*   Batch Size: 16, 32 (Lembre-se que usamos 32 no Dataloader)\n",
        "*   Learning Rate (Adam):  5e-5, 3e-5, 2e-5 (vamos usar 2e-5)\n",
        "*   Numero de épocas (Quantas vezes TODO o dataset é treinado):  2,3,4 (utilizaremos 4):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "u1ozAbS6kN5i"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E6hSvBQkN5i"
      },
      "source": [
        "## Learning Rate Scheduler\n",
        "Em redes neurais é útil diminuir a taxa de aprendizado (learning rate) conforme as épocas vão aumentando para que possamos evitar que o modelo entre em um estado \"caótico\" com taxas grandes ou o \"falso míninmo\" com taxas pequenas. A ideia é ir ajustando conforme as épocas vão passando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "We7Bwo0ekN5i"
      },
      "outputs": [],
      "source": [
        "#ESTA CLASSE FARÁ O AGENDAMENTO\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 4 #QUANTIDADE DE ÉPOCAS\n",
        "\n",
        "#PARA CALCULAR A QUANTIDADE DE PASSOS É A QTD DE BATCHS * ÉPOCAS\n",
        "total_steps = epochs * len(train_dataloader)\n",
        "\n",
        "#CRIANDO O AGENDADOR\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, #VALOR PADRÃO\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "w-FiwiqOkN5i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "# FUNÇÃO  QUE CALCULA A ACURÁCIA DO MODELO (PREDIÇÕES vs LABELS)\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "# FUNÇÃO QUE FORMATA O HORÁRIO\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "324ubfF4kN5i"
      },
      "source": [
        "## Loop de Treinamento\n",
        "Não é só chamar alguma função para treinar o modelo. Precisamos criar um loop que se repita a quantidade de épocas especificadas executando as atividades abaixo. A cada passagem, também faremos uma avaliação do modelo:\n",
        "\n",
        "Loop de treinamento\n",
        "*   Desempacotar os dados de entrada e os labels\n",
        "*   Carregar os dados para a GPU\n",
        "*   Limpar os gradientes calculados na passagem anterior (no pytorch os gradientes são acumulados por padrão. pode ser útil para RNN, mas não no caso de transformers.\n",
        "* Forward Pass (Passar os dados pela rede)\n",
        "* Backward Pass (backpropagation)\n",
        "* Pedir para a rede atualizar os parâmetros (optimizer.step())\n",
        "* Monitar as variáveis para saber o progresso\n",
        "\n",
        "Loop de avaliação\n",
        "* Desempacotar os dados de entrada e os labels\n",
        "* Carregar os dados para a GPU\n",
        "* Forward Pass (Passar os dados pela rede)\n",
        "* Computar a perda na nossa validação e monitorar as variáveis para saber o progresso.\n",
        "\n",
        "**Antes, vamos criar duas funções de ajuda. Uma para calcular a acurácia do modelo e outra para formatar o horário**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYF6WeXokN5i",
        "outputId": "c59a1de4-1eb4-4859-a764-4f7213bb682a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Validation...\n",
            "  Acurácia: 0.78\n",
            "  Tempo de Validação: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "Running Validation...\n",
            "  Acurácia: 0.80\n",
            "  Tempo de Validação: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "Running Validation...\n",
            "  Acurácia: 0.78\n",
            "  Tempo de Validação: 0:00:04\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "Running Validation...\n",
            "  Acurácia: 0.78\n",
            "  Tempo de Validação: 0:00:04\n",
            "FIM DO TREINAMENTO\n"
          ]
        }
      ],
      "source": [
        "\"\"\"**AGORA VEM O LOOP DE TREINAMENTO :)**\"\"\"\n",
        "\n",
        "import random\n",
        "\n",
        "# PRIMEIRO PRECISAMOS GARANTIR A REPRODUTIBILIDADE\n",
        "# USANDO OS SEEDS DO PYTORCH, GARANTIMOS QUE OS VALORES SERÃO INICIADOS DA MESMA FORMA\n",
        "# VAMOS SETAR O MESMO VALOR EM DIFERENTES LUGARES\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# CRIANDO UMA LISTA QUE IRÁ ARMZENAR LOSS AO FIM DE CADA ÉPOCA\n",
        "loss_values = []\n",
        "\n",
        "# CRIANDO O LOOP DAS ÉPOCAS\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # MEDIR QUANTO TEMPO UMA ÉPOCA LEVA\n",
        "    t0 = time.time()\n",
        "\n",
        "    # RESETANDO O LOSS PARA ESTA ÉPOCA\n",
        "    total_loss = 0\n",
        "\n",
        "    #COLOCANDO O MODELO NO MODO DE TREINAMENTO\n",
        "    #ESSE COMANDO NÃO CHAMA O TREINAMENTO, APENAS AVISA O MODELO PARA FAZER AJUSTES DE DROPOUTS\n",
        "    model.train()\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    # UM LOOP PARA CADA BATCH  DENTRO DA ÉPOCA\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # PRECISAMOS DESPEMPACOTAR O BATCH E CARREGAR NA GPU\n",
        "        # BATCH CONTEM TRÊS TENSORES\n",
        "        #   [0]: ID DE INPUT\n",
        "        #   [1]: ATTENTION MASKS\n",
        "        #   [2]: LABELS\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        #PRECISAMOS LIMPAR O GRADIENTE ANTES DE BACKPROP\n",
        "        #PYTORCH NAO FAZ ISSO AUTOMÁTICO\n",
        "        model.zero_grad()\n",
        "\n",
        "        #AGORA VAMOS FAZER UMA PASSAGEM (FORWARD PASS)\n",
        "        #O RESULTADO SERÁ LOSS (NÃO SERÁ A PREDIÇÃO PQ PASSAMOS OS LABELS)\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None, #USADO QUANDO É NEXT SEQUENCE\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        #O MODELO RETORNA UMA TUPLA.\n",
        "        #VAMOS PEGAR O VALOR DA TUPLA\n",
        "        loss = outputs[0]\n",
        "        hidden_state = outputs[2]\n",
        "\n",
        "\n",
        "        # VAMOS ARMAZENAR O HIDDEN STATE E ATENÇÃO TB\n",
        "\n",
        "\n",
        "\n",
        "        #VAMOS ACUMULAR O VALOR NO TOTAL DE LOSS DA ÉPOCA\n",
        "        # .item() RETORNA UM VALOR PYTHON DE UM TENSOR\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        #AGORA VAMOS FAZER O BACKWARD PARA CALCULAR O GRADIENTE\n",
        "        loss.backward()\n",
        "\n",
        "        # PASSO NECESSÁRIO\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # O OTIMIZADOR VAI ATUALIZAR OS PARAMETROS COM BASE NO GRADIENTE\n",
        "        optimizer.step()\n",
        "\n",
        "        # ATUALIZANDO O LEARNING RATE\n",
        "        scheduler.step()\n",
        "\n",
        "    # APOS TODOS OS BATCH DE UMA EPOCA\n",
        "    # CACLULA AVERAGE LOSS COM BASE NO TREINAMENTO (TAMANHO DO DATASET)\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    #ARMAZENA O LOSS NA LISTA (PARA DEPOIS SER PLOTADO NO GRAFICO)\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    # DENTRO DE CADA ÉPOCA TAMBÉM VAMOS RODAR UMA AVALIAÇÃO\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    # COLOCANDO O MODELO NO MODO DE AVALIAÇÃO (SAINDO DO MODULO DE TREINAMENTO)\n",
        "    model.eval()\n",
        "\n",
        "    # CRIANDO VARIÁVEIS DE MONITORAMENTO\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # LOOP PARA AVALIAR CADA BATCH DE TREINAMENTO\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # PEDE AO MODELO PARA NAO COMPUTAR GRADIENTES (É VALIDAÇÃO, NÃO TREINAMENTO)\n",
        "        with torch.no_grad():\n",
        "          # FORWARD PASS PARA CALCULAR OS LOGITS DA PREDIÇÃO\n",
        "          outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "        # O RESULTADO DO MODELO AGORA NÃO SERÁ LOSS\n",
        "        # SERÁ 'LOGITS', VALOR DE SAIDA ANTES DE UMA FUNÇÃO DE ATIVAÇÃO (SOFTMAX POR EXEMPLO)\n",
        "        # COMO É UMA CLASSIFICAÇÃO BINÁRIA, SÓ OS LOGITS SERVEM\n",
        "        # DEPENDENDO DO MODELO SERIA NECESSÁRIO UM SOFTMAX\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # MOVER OS LOGITS E OS LABELS PARA A CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        #CALCULAR ACURÁCIA CHAMANDO A FUNÇÃO QUE CRIAMOS ANTERIORMENTE\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # ACUMULAR O TOTAL DA ACURÁCIA\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # TRACKEAR O NUMERO DE BATCHS\n",
        "        nb_eval_steps +=1\n",
        "\n",
        "    # EXIBINDO DADOS FINAIS\n",
        "    print(\"  Acurácia: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Tempo de Validação: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "#FIM DAS EPOCAS\n",
        "print(\"FIM DO TREINAMENTO\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5OdYfmfo4hS"
      },
      "source": [
        "\n",
        "## Mostrando o gráfico LOSS por época"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "wDrLQTM-pCy7",
        "outputId": "fbe2f925-8118-4212-b465-ce472453034c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A58ecJiHpRh0"
      },
      "source": [
        "## Executando e Testando o modelo\n",
        "\n",
        "Agora que o modelo está treinado, podemos executá-lo. Nesta seção vamos fazer alguns testes. O primeiro ponto é preparar os dados (assim como fizemos na fase de treinamento), mas desta vez não precisamos dos labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "aMtIAYXwpYqb"
      },
      "outputs": [],
      "source": [
        "# FUNÇÃO QUE VALIDA O MODELO\n",
        "def Validar_Modelo(prediction_dataloader, batch_size):\n",
        "  #ARMAZENAR RESULTADOS\n",
        "  resultado_predicoes = []\n",
        "  resultados_esperados = []\n",
        "  falsos_positivos = []\n",
        "  falsos_negativos = []\n",
        "  verdadeiros_positivos = []\n",
        "  verdadeiros_negativos =[]\n",
        "  nb_eval_steps = 0\n",
        "  eval_accuracy = 0\n",
        "  tmp_eval_accuracy = 0\n",
        "  for batch in prediction_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    # PEDE AO MODELO PARA NAO COMPUTAR GRADIENTES (É VALIDAÇÃO, NÃO TREINAMENTO)\n",
        "    with torch.no_grad():\n",
        "      # FORWARD PASS PARA CALCULAR OS LOGITS DA PREDIÇÃO\n",
        "      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    # O RESULTADO DO MODELO AGORA NÃO SERÁ LOSS\n",
        "    # SERÁ 'LOGITS', VALOR DE SAIDA ANTES DE UMA FUNÇÃO DE ATIVAÇÃO (SOFTMAX POR EXEMPLO)\n",
        "    # COMO É UMA CLASSIFICAÇÃO BINÁRIA, SÓ OS LOGITS SERVEM\n",
        "    # DEPENDENDO DO MODELO SERIA NECESSÁRIO UM SOFTMAX\n",
        "    # TAMBÉM É POSSIVEL PEGAR A ATENÇÃO E OS HIDDEN STATES\n",
        "    logits = outputs[0]\n",
        "    attention=outputs[-1]\n",
        "    all_hidden_state = outputs[-2]\n",
        "\n",
        "    # MOVER OS LOGITS E OS LABELS PARA A CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    reconstruct_input_id = b_input_ids.to('cpu').numpy()\n",
        "\n",
        "    # LOOP PARA VISUALIZAR CADA SETENÇA\n",
        "    for logit, label, inputs, att in zip(logits, label_ids, reconstruct_input_id, attention):\n",
        "      resultado_predicoes.append(np.argmax(logit))\n",
        "      resultados_esperados.append(label)\n",
        "      # LOOP PARA IDENTIFICAR FALSOS POSITIVIOS, FALSOS NEGATIVOS e CORRETOS\n",
        "      if (label != np.argmax(logit)):\n",
        "        if (label == 1 and np.argmax(logit) == 0):\n",
        "          falsos_negativos.append(inputs)\n",
        "          #captum(inputs,label,logit, \"fn\")\n",
        "        elif(label == 0 and np.argmax(logit) == 1):\n",
        "          falsos_positivos.append(inputs)\n",
        "          #captum(inputs,label,logit, \"fp\")\n",
        "      else:\n",
        "        if (label == 1 and np.argmax(logit) == 1):\n",
        "          verdadeiros_positivos.append(inputs)\n",
        "          #captum(inputs,label,logit, \"tp\")\n",
        "        elif (label == 0 and np.argmax(logit) == 0):\n",
        "          verdadeiros_negativos.append(inputs)\n",
        "          #captum(inputs,label,logit, \"tn\")\n",
        "\n",
        "    #CALCULAR ACURÁCIA CHAMANDO A FUNÇÃO QUE CRIAMOS ANTERIORMENTE\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    # ACUMULAR O TOTAL DA ACURÁCIA\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    # TRACKEAR O NUMERO DE BATCHS\n",
        "    nb_eval_steps +=1\n",
        "    #wait = input(\"PRESS ENTER TO CONTINUE.\")\n",
        "\n",
        "  # RELATÓRIO FINAL\n",
        "  print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "\n",
        "  from sklearn.metrics import accuracy_score\n",
        "  print(\"Accuracia: \", accuracy_score(resultados_esperados, resultado_predicoes))\n",
        "\n",
        "  from sklearn.metrics import f1_score\n",
        "  print(\"F1 Score:\", f1_score(resultados_esperados, resultado_predicoes, average='weighted'))\n",
        "\n",
        "  from sklearn.metrics import recall_score\n",
        "  print(\"Recall:\", recall_score(resultados_esperados, resultado_predicoes, average='weighted'))\n",
        "\n",
        "  from sklearn.metrics import precision_score\n",
        "  print(\"Precision: \", precision_score(resultados_esperados, resultado_predicoes, average='weighted'))\n",
        "\n",
        "  #listar_falsospositivos(falsos_positivos)\n",
        "  #attrib2csv(attrib_falsospositivo, \"falsos_positivos.csv\")\n",
        "  #attrib2csv(attrib_falsosnegativos, \"falsos_negativos.csv\")\n",
        "  #attrib2csv(attrib_verdadeirospositivos, \"verdadeiros_positivos.csv\")\n",
        "  #attrib2csv(attrib_verdadeironegativos, \"verdadeiros_negativos.csv\")\n",
        "\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "  tn, fp, fn, tp = confusion_matrix(resultados_esperados, resultado_predicoes).ravel()\n",
        "  print (\"True Negative: \", tn)\n",
        "  print (\"False Positive: \", fp)\n",
        "  print (\"False Negative: \", fn)\n",
        "  print (\"True Positive: \", tp)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1hHoaZqqDag"
      },
      "source": [
        "### Tratando os dados para chamar a validação\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "x4RvhcaMrG2B"
      },
      "outputs": [],
      "source": [
        "tokenizer.enable_truncation(max_length=100)\n",
        "tokenizer.enable_padding()\n",
        "\n",
        "# TOKENINZA EM BATCH TODAS AS SENTENÇAS\n",
        "# TEM QUE USAR .TOLIST PARA CONVERTER POR LISTA. SENTENCAS É UM ARRAY NUMPY\n",
        "output = tokenizer.encode_batch(sentencas)\n",
        "\n",
        "# O TOKENIZER RETORAR UMA LISTA DE OBJETOS DO TIPO TOKENIZER\n",
        "# PRECISAMOS PEGAR OS ATRIBUTOS IDS E MASKS E ADICIONAR PARA LISTAS\n",
        "# OS OBJETOS TEM O ATRIBUTO IDS(IDS), TOKENS (TOKENS) E attention_mask\n",
        "# PRECISAMOS FAXER O FOR PARA PEGAR CADA UM E DEPOIS CRIAR A LISTA\n",
        "ids=[x.ids for x in output]\n",
        "tokens = [x.tokens for x in output]\n",
        "attention_mask = [x.attention_mask for x in output]\n",
        "\n",
        "# AGORA PRECISAMOS CONVERTER DE NUMPY PARA TENSOR\n",
        "prediction_input = torch.tensor(ids)\n",
        "prediction_mask = torch.tensor(attention_mask)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# GARANTINDO QUE TODOS OS CAMPOS TEM O MESMO TAMANHO\n",
        "#print (prediction_input.size(0))\n",
        "#print (prediction_mask.size(0))\n",
        "#print (prediction_labels.size(0))\n",
        "\n",
        "# DEFININDO O TAMANHO DO BATCH\n",
        "batch_size = 32\n",
        "\n",
        "# CRIANDO O DATALOADER\n",
        "prediction_data = TensorDataset(prediction_input, prediction_mask, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_prediction_dataloader(tokenizer, sentencas, labels, batch_size=32, max_length=100):\n",
        "    # Configura o tokenizer\n",
        "    tokenizer.enable_truncation(max_length=max_length)\n",
        "    tokenizer.enable_padding()\n",
        "\n",
        "    # Tokeniza em batch\n",
        "    output = tokenizer.encode_batch(sentencas)\n",
        "\n",
        "    # Extrai ids e masks\n",
        "    ids = [x.ids for x in output]\n",
        "    attention_mask = [x.attention_mask for x in output]\n",
        "\n",
        "    # Converte para tensores\n",
        "    prediction_input = torch.tensor(ids)\n",
        "    prediction_mask = torch.tensor(attention_mask)\n",
        "    prediction_labels = torch.tensor(labels)\n",
        "\n",
        "    # Cria o DataLoader\n",
        "    prediction_data = TensorDataset(prediction_input, prediction_mask, prediction_labels)\n",
        "    prediction_sampler = SequentialSampler(prediction_data)\n",
        "    prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
        "\n",
        "    return prediction_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH9Vpl43nv-K",
        "outputId": "9bfa88a1-4f5e-4105-a1ea-855f59b62302"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Accuracy: 0.91\n",
            "Accuracia:  0.907981220657277\n",
            "F1 Score: 0.907730557656237\n",
            "Recall: 0.907981220657277\n",
            "Precision:  0.9075677970279258\n",
            "True Negative:  1351\n",
            "False Positive:  91\n",
            "False Negative:  105\n",
            "True Positive:  583\n"
          ]
        }
      ],
      "source": [
        "Validar_Modelo(prediction_dataloader, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing on whole corpus of data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/var/folders/s6/ct_3z9zx0n90y_kng03jqj5r0000gn/T/ipykernel_15292/4251725632.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load('../../ig-models/2025-04-06-bert-v1.pkl', map_location='cpu')\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(29794, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# 1. Recreate the model architecture (must match training)\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'neuralmind/bert-base-portuguese-cased',\n",
        "    num_labels=2,\n",
        "    output_attentions=True,\n",
        "    output_hidden_states=True,\n",
        ")\n",
        "\n",
        "# 2. Load the state_dict\n",
        "state_dict = torch.load('../../ig-models/2025-04-06-bert-v1.pkl', map_location='cpu')\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "model.eval()  # Set to evaluation mode\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import full binary dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mais um lixo</td>\n",
              "      <td>1</td>\n",
              "      <td>HateBR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Essa nao tem vergonha na cara!!</td>\n",
              "      <td>1</td>\n",
              "      <td>HateBR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Essa mulher é doente.pilantra!</td>\n",
              "      <td>1</td>\n",
              "      <td>HateBR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Comunista safada...</td>\n",
              "      <td>1</td>\n",
              "      <td>HateBR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vagabunda. Comunista. Mentirosa. O povo chilen...</td>\n",
              "      <td>1</td>\n",
              "      <td>HateBR</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label  source\n",
              "0                                       Mais um lixo      1  HateBR\n",
              "1                    Essa nao tem vergonha na cara!!      1  HateBR\n",
              "2                     Essa mulher é doente.pilantra!      1  HateBR\n",
              "3                                Comunista safada...      1  HateBR\n",
              "4  Vagabunda. Comunista. Mentirosa. O povo chilen...      1  HateBR"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_parquet('../../data/processed_data/concat_binary_df.parquet')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "55035\n",
            "55035\n",
            "Encoding(num_tokens=60, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "['[CLS]', 'mais', 'um', 'lixo', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ],
      "source": [
        "colab = False\n",
        "labels = df['label'].values\n",
        "sentencas = [sentenca.lower() for sentenca in df['text'].values]\n",
        "tokenizer, ids, attention_mask, output = create_tokenizer_and_tokenize(sentencas, vocab_path=\"vocab.txt\", colab=colab, max_length=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction_dataloader = create_prediction_dataloader(tokenizer, sentencas, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mValidar_Modelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprediction_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[40], line 20\u001b[0m, in \u001b[0;36mValidar_Modelo\u001b[0;34m(prediction_dataloader, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# PEDE AO MODELO PARA NAO COMPUTAR GRADIENTES (É VALIDAÇÃO, NÃO TREINAMENTO)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     19\u001b[0m   \u001b[38;5;66;03m# FORWARD PASS PARA CALCULAR OS LOGITS DA PREDIÇÃO\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_input_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb_input_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# O RESULTADO DO MODELO AGORA NÃO SERÁ LOSS\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# SERÁ 'LOGITS', VALOR DE SAIDA ANTES DE UMA FUNÇÃO DE ATIVAÇÃO (SOFTMAX POR EXEMPLO)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# COMO É UMA CLASSIFICAÇÃO BINÁRIA, SÓ OS LOGITS SERVEM\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# DEPENDENDO DO MODELO SERIA NECESSÁRIO UM SOFTMAX\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# TAMBÉM É POSSIVEL PEGAR A ATENÇÃO E OS HIDDEN STATES\u001b[39;00m\n\u001b[1;32m     26\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1696\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1696\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1702\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1703\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1704\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1710\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:383\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m output_attentions \u001b[38;5;129;01mor\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# TODO: Improve this warning with e.g. `model.config._attn_implementation = \"manual\"` once implemented.\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    377\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`attn_implementation=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meager\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` when loading the model.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    382\u001b[0m     )\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m bsz, tgt_len, _ \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    395\u001b[0m query_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(hidden_states))\n",
            "File \u001b[0;32m~/github/hate-speech/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:344\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m attention_probs \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[0;32m--> 344\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    347\u001b[0m new_context_layer_shape \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size,)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "Validar_Modelo(prediction_dataloader, batch_size=32)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
